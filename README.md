# llama-chat-offline--LLaMATE
ğŸ’¬ Offline Chatbot UI using Streamlit + Ollama + LLaMA + Image/Voice/Doc Q&amp;A

An ultra-modern, **fully offline chatbot** UI using [Ollama](https://ollama.com), [LLaMA 3](https://ollama.com/library/llama3), and [Streamlit](https://streamlit.io).

## ğŸš€ Features

âœ… Chat with powerful open-source LLMs  
âœ… 100% Private â€“ Works fully offline (No internet needed)  
âœ… Upload documents (TXT) and ask questions  
âœ… Upload images for Visual Q&A ğŸ–¼ï¸  
âœ… Voice input support ğŸ¤  
âœ… Customizable UI with avatars, markdown, and themes  
âœ… Download chat as `.txt` or `.json`  
âœ… Emoji & markdown-friendly formatting  
âœ… Responsive and user-friendly design

ğŸ› ï¸ Built With
Python

Streamlit

Ollama

LLaMA

SpeechRecognition

Pillow


---

## ğŸ“¦ Run Locally

```bash
# 1. Clone the repo
git clone https://github.com/yourusername/llama-chat-ui-offline.git
cd llama-chat-ui-offline

# 2. Set up Python environment
python -m venv .venv
source .venv/bin/activate        # (Windows: .venv\\Scripts\\activate)

# 3. Install dependencies
pip install -r requirements.txt

# 4. Start Ollama and run model
ollama run llama3

# 5. Launch the app
streamlit run app.py

