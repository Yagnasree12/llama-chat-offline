# Make sure Streamlit is installed before running
try:
    import streamlit as st
except ModuleNotFoundError:
    raise ModuleNotFoundError("Streamlit is not installed. Run `pip install streamlit` before running this app.")

# Then continue with the original content

"""
**LLaMate â€” Your Private Offline AI Assistant**
An ultraâ€‘polished Streamlit Web UI for chatting with local LLaMA models served by **Ollama**.
-------------------------------------------------------------------------------
Run it locally:
```bash
python -m venv .venv && source .venv/bin/activate   # (Windows: .venv\\Scripts\\activate)
pip install -r requirements.txt
streamlit run app.py
```

Requirements (`requirements.txt`):
```
streamlit>=1.34
requests
pillow
speechrecognition
```

Features ğŸ§ª
- Gradient background & glassâ€‘morphism chat bubbles ğŸ¨
- Emojiâ€‘friendly messages ğŸ˜„
- **TXT** document upload â†’ used as context
- **Image** upload for visual Q&A ğŸ–¼ï¸ (image encoded + prompt)
- Custom avatars (ğŸ§‘ / ğŸ¤–)
- Voice input via microphone (offline with PocketSphinx if installed, else Google API) ğŸ™ï¸
- Markdown rendering in replies ğŸ“˜
- Sidebar accent color picker, temperature & topâ€‘p sliders
- Light â‡„ dark theme switch
- Scrollâ€‘locked chat area, autoâ€‘scroll to newest
- Oneâ€‘click download of transcript (TXT / JSON)
- Ollama health badge

Built entirely clientâ€‘sideâ€”no data leaves your machine.
"""

# ...[rest of code remains unchanged, as previously saved]...
